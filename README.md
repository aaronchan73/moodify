# Moodify

## Inspiration

As music lovers, we always choose songs based on how we feel. If we're happy, we might go for something upbeat, like hip-hop. If we're sad, something slower like ballads are the way to go. We wanted to make a web app that lets users explore songs they might not listen to usually, based on their mood.

## What it does

Moodify allows users to input their current emotion, and then is recommended different songs based on how they're feeling!

## How we built it

For our front-end, we used React and Tailwind CSS for a smooth coding experience when creating the web application. For our back-end, we used the Spotify API to retrieve recommended songs, which can be stored in Firebase's NoSQL database Firestore.

## Challenges we ran into

We initially wanted to implement Computer Vision using GCP's Cloud Vision API. However, we were only able to used it for a Node.js application rather than for our React project, so we ultimately scrapped the idea.

## Accomplishments that we're proud of

We're proud of being able to create a full-stack web application that is both fun and useful.

## What we learned

We learned how to use React, Tailwind CSS, Firebase/Firestore, and Spotify's API.

## What's next for Moodify

Incorporate Computer Vision to sense the user's mood directly, which allows for recommendations on the spot.
